"""
====================================================================
REST â†’ MCP DASHBOARD  â€¢  v2025-06
====================================================================

4 Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ° (Ğ²ĞºĞ»Ğ°Ğ´ĞºĞ¸ Streamlit):

1. ğŸ’¬ CHAT
   â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ° Ñ GPT-3.5/4.
   â€¢ GPT Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ²Ğ¸Ğ´Ğ¸Ñ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº function-tools Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ MCP-ÑĞµÑ€Ğ²ĞµÑ€Ğ°
     Ğ¸ Ğ¿Ñ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¸Ñ… Ñ‡ĞµÑ€ĞµĞ· /tools/call.

2. ğŸ”„ CONVERT
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Swagger/OpenAPI (JSON Ğ¸Ğ»Ğ¸ YAML) Ğ¿Ğ¾ URL.
   â€¢ (ĞĞ¿Ñ†.) GPT-Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¹ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ¾Ğ².
   â€¢ Ğ“Ğ°Ğ»Ğ¾Ñ‡ĞºĞ¸ Ğ´Ğ»Ñ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ/Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ².
   â€¢ Ğ—Ğ°Ğ¿ÑƒÑĞº/Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞº Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ MCP-ÑĞµÑ€Ğ²ĞµÑ€Ğ° Ğ½Ğ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ€Ñ‚Ñƒ.

3. ğŸ—‚ PROJECTS
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ/ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ².  Ğ’ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğµ â€” Ğ¾Ğ´Ğ¸Ğ½ OpenAI-ĞºĞ»ÑÑ‡.
   â€¢ ĞŸĞµÑ€ĞµÑ‡ĞµĞ½ÑŒ Ğ²ÑĞµÑ… API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ¸ Ğ¸Ñ… Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ
     (Â«âœ… Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Â» Ğ¸Ğ»Ğ¸ Â«â¹ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Â»).

4. âš™ï¸ API SETUP
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ/Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ (URL, Ğ¿Ğ¾Ñ€Ñ‚, auth-Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸
     Ğ¸Ğ»Ğ¸ query-ĞºĞ»ÑÑ‡, Ğ¸Ğ¼Ñ).  ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ Ñ‚Ğ°ĞºĞ¶Ğµ spec, enabled-map,
     Ñ‚Ñ€ĞµĞ´ ÑĞµÑ€Ğ²ĞµÑ€Ğ° Ğ¸ Ğ»Ğ¾Ğ³Ğ¸.

---------------------------------------------------------------------
Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸  (requirements.txt):

    streamlit>=1.34
    requests>=2.31
    httpx>=0.27
    pyyaml>=6.0
    pydantic>=2.6
    openai>=1.25
    mcp>=0.3               # FastMCP SDK
    python-dotenv>=1.0

---------------------------------------------------------------------
Ğ¤Ğ°Ğ¹Ğ» .env  (Ğ»ĞµĞ¶Ğ¸Ñ‚ Ñ€ÑĞ´Ğ¾Ğ¼ Ñ ÑÑ‚Ğ¸Ğ¼ app.py):

    OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

---------------------------------------------------------------------
Ğ—Ğ°Ğ¿ÑƒÑĞº:

    streamlit run app.py
---------------------------------------------------------------------
"""

import os, json, yaml, threading, time, copy
from typing import Dict, Tuple, Set

import streamlit as st
import requests, httpx, openai
from dotenv import load_dotenv
from mcp.server.fastmcp import FastMCP

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ĞŸĞĞ›Ğ•Ğ—ĞĞ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜                                                  #
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def rerun():
    """Streamlit â‰¥1.30 â†’ st.rerun, ÑÑ‚Ğ°Ñ€Ñ‹Ğµ â†’ experimental_rerun."""
    (getattr(st, "rerun", None) or st.experimental_rerun)()

def load_openapi(url: str) -> Dict:
    """Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ OpenAPI/Swagger Ğ¿Ğ¾ URL Ğ¸ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ."""
    r = requests.get(url, timeout=20)
    r.raise_for_status()
    txt = r.text.lstrip()
    try:
        return json.loads(txt)        # JSON
    except json.JSONDecodeError:
        return yaml.safe_load(txt)    # YAML

def gpt_describe(spec: Dict, api_key: str):
    """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ/Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ description Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ operation."""
    if not api_key:
        return
    openai.api_key = api_key
    for path, meths in spec["paths"].items():
        for method, op in meths.items():
            prompt = (f"ĞĞ¿Ğ¸ÑˆĞ¸ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ° Ğ¾Ğ´Ğ½Ğ¸Ğ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ĞµĞ¼:\n"
                      f"{method.upper()} {path}")
            try:
                resp = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=40, temperature=0)
                op["description"] = resp.choices[0].message.content.strip()
            except Exception as e:
                print("GPT error:", e)

def filter_spec(spec: Dict, allowed: Set[Tuple[str, str]]) -> Dict:
    """Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒ ĞºĞ¾Ğ¿Ğ¸Ñ spec, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰ÑƒÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ allowed (path, method)."""
    s2 = copy.deepcopy(spec)
    for p in list(s2["paths"].keys()):
        for m in list(s2["paths"][p].keys()):
            if (p, m.lower()) not in allowed:
                s2["paths"][p].pop(m)
        if not s2["paths"][p]:
            s2["paths"].pop(p)
    return s2

def make_http_client(base: str, headers: Dict, qparams: Dict, logger):
    """httpx.AsyncClient Ñ Ñ…ÑƒĞºĞ¾Ğ¼ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ."""
    def hook(resp: httpx.Response):
        logger(f"{resp.request.method} {resp.request.url} â†’ {resp.status_code}")
    return httpx.AsyncClient(base_url=base, headers=headers,
                             params=qparams, timeout=20,
                             event_hooks={"response": [hook]})

def log_line(project: dict, api_name: str, msg: str):
    project["apis"][api_name].setdefault("logs", []).append(
        f"{time.strftime('%H:%M:%S')}  {msg}"
    )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ SESSION_STATE                                      #
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
load_dotenv()
OPENAI_ENV = os.getenv("OPENAI_API_KEY", "")

st.set_page_config(page_title="REST â†’ MCP", layout="wide")

state = st.session_state
state.setdefault("projects", {})        # name â†’ project-dict
state.setdefault("proj_sel", None)      # Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚
state.setdefault("api_sel",  None)      # Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ
state.setdefault("chat",     [])        # [(role, text)]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  SIDEBAR NAVIGATION                                               #
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PAGES = ["ğŸ’¬ Chat", "ğŸ”„ Convert", "ğŸ—‚ Projects", "âš™ï¸ API Setup"]
page = st.sidebar.radio("ĞĞ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ñ", PAGES)

# highlight selected project
if state.get("proj_sel"):
    st.sidebar.success(f"ĞŸÑ€Ğ¾ĞµĞºÑ‚: {state['proj_sel']}")
else:
    st.sidebar.info("ĞŸÑ€Ğ¾ĞµĞºÑ‚ Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Projects â”€â”€â”€
if page == "ğŸ—‚ Projects":
    st.header("ğŸ—‚ Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ğ¼Ğ¸")

    proj_names = list(state["projects"])
    chosen = st.selectbox("ĞŸÑ€Ğ¾ĞµĞºÑ‚",
                          ["< ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ >"] + proj_names,
                          index=(proj_names.index(state["proj_sel"]) + 1
                                 if state["proj_sel"] in proj_names else 0))
    creating_new = chosen == "< ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ >"

    project = {"name": "", "openai": OPENAI_ENV, "apis": {}} \
              if creating_new else state["projects"][chosen]
    project["name"] = st.text_input("ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°", project["name"])
    project["openai"] = st.text_input("OpenAI API-ĞºĞ»ÑÑ‡",
                                      project["openai"], type="password",
                                      help="ĞŸÑƒÑÑ‚Ğ¾ â†’ Ğ±ĞµÑ€Ñ‘Ñ‚ÑÑ Ğ¸Ğ· .env")

    if st.button("ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚"):
        if not project["name"]:
            st.warning("Ğ˜Ğ¼Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾.")
        else:
            state["projects"][project["name"]] = project
            state["proj_sel"] = project["name"]
            rerun()

    if not creating_new:
        st.divider()
        st.subheader("API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸ Ğ² Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğµ")
        for api_name, cfg in project["apis"].items():
            running = cfg.get("thread") and cfg["thread"].is_alive()
            badge = "âœ…" if running else "â¹"
            st.write(f"{badge} **{api_name}**  â€”  {cfg['url']}  (:{cfg['port']})")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ API Setup â”€â”€
elif page == "âš™ï¸ API Setup":
    st.header("âš™ï¸ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ")
    if not state["proj_sel"]:
        st.info("Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ/Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ²Ğ¾ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞµ Â«ProjectsÂ».")
        st.stop()

    project = state["projects"][state["proj_sel"]]
    api_names = list(project["apis"])
    chosen_api = st.selectbox("API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ",
                              ["< ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ >"] + api_names,
                              index=(api_names.index(state["api_sel"]) + 1
                                     if state["api_sel"] in api_names else 0))
    creating_api = chosen_api == "< ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ >"

    api = {"name": "", "url": "", "port": 8000,
           "header_name": "", "header_val": "",
           "query_name": "", "query_val": "",
           "spec": None, "enabled": {}, "thread": None, "logs": []} \
          if creating_api else project["apis"][chosen_api]

    col1, col2 = st.columns(2)
    with col1:
        api["name"] = st.text_input("API-Ğ¸Ğ¼Ñ", api["name"])
        api["url"]  = st.text_input("URL ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸", api["url"])
        api["port"] = st.number_input("ĞŸĞ¾Ñ€Ñ‚ MCP", 1024, 65535, api["port"])
    with col2:
        api["header_name"] = st.text_input("Auth header", api["header_name"])
        api["header_val"]  = st.text_input("Header value", api["header_val"])
        api["query_name"]  = st.text_input("Auth query", api["query_name"])
        api["query_val"]   = st.text_input("Query value", api["query_val"])

    if st.button("ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ API"):
        if not api["name"] or not api["url"]:
            st.warning("Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Ğ¸Ğ¼Ñ Ğ¸ URL ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸.")
        else:
            project["apis"][api["name"]] = api
            state["api_sel"] = api["name"]
            rerun()

    # Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶Ğ°ĞµĞ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ Ğ»Ğ¾Ğ³Ğ¸ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ
    if not creating_api:
        st.divider()
        running = api.get("thread") and api["thread"].is_alive()
        st.write("Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ MCP:",
                 "âœ… **Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½**" if running else "â¹ **Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½**")
        st.text_area("Ğ›Ğ¾Ğ³Ğ¸ (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 20)",
                     "\n".join(api["logs"][-20:]), height=200)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONVERT â”€â”€â”€
elif page == "ğŸ”„ Convert":
    st.header("ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° OpenAPI Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞº MCP")
    if not state["proj_sel"] or not state["api_sel"]:
        st.info("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ¸ API Ğ²Ğ¾ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞµ Â«API SetupÂ».")
        st.stop()

    project = state["projects"][state["proj_sel"]]
    api = project["apis"][state["api_sel"]]

    # 1. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸
    if st.button("ğŸ”„ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ"):
        try:
            spec = load_openapi(api["url"])
        except Exception as e:
            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ°: {e}")
            st.stop()

        gpt_describe(spec, project["openai"])
        api["spec"] = spec
        # ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ enabled map, ĞµÑĞ»Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾
        eps = {(p, m.lower()) for p, v in spec["paths"].items() for m in v}
        if not api["enabled"]:
            api["enabled"] = {f"{m} {p}": True for (p, m) in eps}

        rerun()

    # 2. Ğ’Ñ‹Ğ±Ğ¾Ñ€ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ¾Ğ²
    if api.get("spec"):
        st.subheader("Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ/Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹")
        cols = st.columns(2)
        for i, (p, meths) in enumerate(api["spec"]["paths"].items()):
            for m in meths:
                key = f"{m} {p}"
                with cols[i % 2]:
                    api["enabled"][key] = st.checkbox(
                        key, value=api["enabled"][key])

        # 3. Ğ—Ğ°Ğ¿ÑƒÑĞº MCP
        if st.button("ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ / ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ MCP"):
            allowed = {(p, m.lower()) for p, m in
                       [k.split(" ", 1)[::-1]
                        for k, v in api["enabled"].items() if v]}
            spec_filtered = filter_spec(api["spec"], allowed)

            base = (api["spec"].get("servers", [{"url": ""}])[0]["url"]).rstrip("/")
            headers = ({api["header_name"]: api["header_val"]}
                       if api["header_name"] else {})
            qparams = ({api["query_name"]: api["query_val"]}
                       if api["query_name"] else {})

            client = make_http_client(base, headers, qparams,
                                      lambda m: log_line(project, api["name"], m))

            try:
                mcp = FastMCP.from_openapi(
                    spec_filtered, client,
                    name=f"{project['name']}_{api['name']}",
                    host="0.0.0.0", port=api["port"])
            except Exception as e:
                st.error(f"FastMCP error: {e}")
                st.stop()

            def run_server():
                log_line(project, api["name"], f"ğŸš€ MCP start :{api['port']}")
                mcp.run()

            # Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° ÑÑ‚Ğ°Ñ€Ğ¾Ğ³Ğ¾ ÑĞµÑ€Ğ²ĞµÑ€Ğ° Ğ½Ğµ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ° (FastMCP Ğ½ĞµÑ‚ stop())
            t = threading.Thread(target=run_server, daemon=True)
            t.start()
            api["thread"] = t
            api["logs"] = []
            rerun()

    # Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ°
    running = api.get("thread") and api["thread"].is_alive()
    if running:
        st.success(f"MCP-ÑĞµÑ€Ğ²ĞµÑ€ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ Ğ½Ğ° :{api['port']}")
    st.text_area("Ğ›Ğ¾Ğ³Ğ¸ ÑĞµÑ€Ğ²ĞµÑ€Ğ°", "\n".join(api.get("logs", [])[-20:]),
                 height=200)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CHAT â”€â”€â”€â”€â”€â”€
elif page == "ğŸ’¬ Chat":
    st.header("ğŸ’¬ Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ñ‡Ğ°Ñ‚ Ñ MCP")

    # ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ²ÑĞµÑ… Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ñ… ÑĞµÑ€Ğ²ĞµÑ€Ğ¾Ğ²
    running_servers = [
        (pj_name, api_name, cfg)
        for pj_name, pj in state["projects"].items()
        for api_name, cfg in pj["apis"].items()
        if cfg.get("thread") and cfg["thread"].is_alive()
    ]
    if not running_servers:
        st.info("ĞĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‰Ğ¸Ñ… MCP-ÑĞµÑ€Ğ²ĞµÑ€Ğ¾Ğ².")
        st.stop()

    sel_label = st.selectbox(
        "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ MCP-ÑĞµÑ€Ğ²ĞµÑ€",
        [f"{pj}/{api}  (:{cfg['port']})" for pj, api, cfg in running_servers]
    )
    pj_name, api_name = sel_label.split("  ")[0].split("/")
    chat_cfg = state["projects"][pj_name]["apis"][api_name]
    port = chat_cfg["port"]

    # Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸
    for role, msg in state["chat"]:
        st.chat_message(role).markdown(msg)

    user_msg = st.chat_input("Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµâ€¦")
    if user_msg:
        state["chat"].append(("user", user_msg))
        st.chat_message("user").markdown(user_msg)

        # Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ tools /tools/list
        try:
            tools_json = requests.post(
                f"http://localhost:{port}/tools/list",
                timeout=10).json()
            tools = tools_json["tools"]
        except Exception as e:
            st.error(f"/tools/list error: {e}")
            st.stop()

        functions = [
            {"name": t["name"],
             "description": t["description"],
             "parameters": t["input_schema"]}
            for t in tools
        ]

        openai.api_key = state["projects"][pj_name]["openai"] or OPENAI_ENV
        conv = [{"role": "system",
                 "content": "ĞŸÑ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ MCP-tools."}] + \
               [{"role": r, "content": m} for r, m in state["chat"]]

        while True:
            resp = openai.ChatCompletion.create(
                model="gpt-3.5-turbo-1106",
                messages=conv,
                functions=functions
            )
            msg = resp.choices[0].message

            # ĞµÑĞ»Ğ¸ GPT Ñ…Ğ¾Ñ‡ĞµÑ‚ Ğ²Ñ‹Ğ·Ğ²Ğ°Ñ‚ÑŒ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ
            if "function_call" in msg:
                fc = msg.function_call
                args = json.loads(fc.arguments or "{}")
                try:
                    result = requests.post(
                        f"http://localhost:{port}/tools/call",
                        json={"name": fc.name, "arguments": args},
                        timeout=30).json()
                    tool_answer = result["content"][0]["text"]
                except Exception as e:
                    tool_answer = f"âš ï¸ MCP error: {e}"

                conv.append({"role": "assistant", "name": fc.name,
                             "content": None, "function_call": fc})
                conv.append({"role": "function", "name": fc.name,
                             "content": tool_answer})
            else:
                answer = msg.content
                state["chat"].append(("assistant", answer))
                st.chat_message("assistant").markdown(answer)
                break
