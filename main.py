"""
====================================================================
REST â†’ MCP DASHBOARD  â€¢  v2025-06
====================================================================

4 Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ° (Ğ²ĞºĞ»Ğ°Ğ´ĞºĞ¸ Streamlit):

1. ğŸ’¬ CHAT
   â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ° Ñ GPT-3.5/4.
   â€¢ GPT Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ²Ğ¸Ğ´Ğ¸Ñ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº function-tools Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ MCP-ÑĞµÑ€Ğ²ĞµÑ€Ğ°
     Ğ¸ Ğ¿Ñ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¸Ñ… Ñ‡ĞµÑ€ĞµĞ· /tools/call.

2. ğŸ”„ CONVERT
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ ĞŸĞ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ° Ğ¾ Ñ‚Ğ¾Ğ¼, Ñ‡Ñ‚Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ² Â«API SetupÂ»,
     Ğ° Ğ·Ğ°Ğ¿ÑƒÑĞº MCP Ğ¿ĞµÑ€ĞµĞ½ĞµÑÑ‘Ğ½ Ğ² Â«ChatÂ».

3. ğŸ—‚ PROJECTS
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ/ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ².  Ğ’ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğµ â€” Ğ¾Ğ´Ğ¸Ğ½ OpenAI-ĞºĞ»ÑÑ‡.
   â€¢ ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½ÑƒĞ¶Ğ½Ñ‹Ñ… API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹ Ğ¸Ğ· Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ¸ Ğ¸Ñ… ÑÑ‚Ğ°Ñ‚ÑƒÑ
     (Â«âœ… Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Â» Ğ¸Ğ»Ğ¸ Â«â¹ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Â»).

4. âš™ï¸ API SETUP
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ¼ API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹ (URL, Ğ¿Ğ¾Ñ€Ñ‚, auth-
     Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸ Ğ¸Ğ»Ğ¸ query-ĞºĞ»ÑÑ‡, Ğ¸Ğ¼Ñ). ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ Ğ¿Ğ¾Ğ»Ğ½ÑƒÑ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ,
     ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹ Ñ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ÑĞ¼Ğ¸ Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸, enabled-map, Ñ‚Ñ€ĞµĞ´ ÑĞµÑ€Ğ²ĞµÑ€Ğ°
     Ğ¸ Ğ»Ğ¾Ğ³Ğ¸.
   â€¢ ĞĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹ Ñ‡ĞµÑ€ĞµĞ· Â«Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¸Ğ· ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ°Â».
   â€¢ ĞŸĞ°Ğ¿ĞºĞ° `profiles/` Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ğ¾Ğ´Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ°Ñ€Ñ‚Ğµ,
     Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°.
   â€¢ Ğ’ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸ ÑƒĞ¶Ğµ ĞµÑÑ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² ÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ°Ğ¿ĞºĞµ.

---------------------------------------------------------------------
Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸  (requirements.txt):

    streamlit>=1.34
    requests>=2.31
    httpx>=0.27
    pyyaml>=6.0
    pydantic>=2.6
    openai>=1.25
    mcp>=0.3               # FastMCP SDK
    python-dotenv>=1.0

---------------------------------------------------------------------
Ğ¤Ğ°Ğ¹Ğ» .env  (Ğ»ĞµĞ¶Ğ¸Ñ‚ Ñ€ÑĞ´Ğ¾Ğ¼ Ñ ÑÑ‚Ğ¸Ğ¼ app.py):

    OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

---------------------------------------------------------------------
Ğ—Ğ°Ğ¿ÑƒÑĞº:

    streamlit run app.py
---------------------------------------------------------------------
"""

import os, json, yaml, threading, time, copy
from typing import Dict, Tuple, Set

import streamlit as st
import requests, httpx, openai
from dotenv import load_dotenv
from mcp.server.fastmcp import FastMCP


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ĞŸĞĞ›Ğ•Ğ—ĞĞ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜                                                  #
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def rerun():
    """Streamlit â‰¥1.30 â†’ st.rerun, ÑÑ‚Ğ°Ñ€Ñ‹Ğµ â†’ experimental_rerun."""
    (getattr(st, "rerun", None) or st.experimental_rerun)()


def load_openapi(url: str) -> Dict:
    """Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ OpenAPI/Swagger Ğ¿Ğ¾ URL Ğ¸ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ."""
    r = requests.get(url, timeout=20)
    r.raise_for_status()
    txt = r.text.lstrip()
    try:
        return json.loads(txt)  # JSON
    except json.JSONDecodeError:
        return yaml.safe_load(txt)  # YAML


def gpt_describe(spec: Dict, api_key: str):
    """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ/Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ description Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ operation."""
    if not api_key:
        return
    openai.api_key = api_key
    for path, meths in spec["paths"].items():
        for method, op in meths.items():
            prompt = (
                f"ĞĞ¿Ğ¸ÑˆĞ¸ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ° Ğ¾Ğ´Ğ½Ğ¸Ğ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ĞµĞ¼:\n"
                f"{method.upper()} {path}"
            )
            try:
                resp = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=40,
                    temperature=0,
                )
                op["description"] = resp.choices[0].message.content.strip()
            except Exception as e:
                print("GPT error:", e)


def gpt_mcp_names(spec: Dict, api_key: str) -> Dict[str, str]:
    """Return mapping from operationId to short MCP component names."""
    if not api_key:
        return {}
    openai.api_key = api_key
    names = {}
    for path, meths in spec.get("paths", {}).items():
        for method, op in meths.items():
            op_id = op.get("operationId") or f"{method}_{path.strip('/').replace('/', '_')}"
            prompt = (
                "ĞŸÑ€Ğ¸Ğ´ÑƒĞ¼Ğ°Ğ¹ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾Ğµ Ğ¸Ğ¼Ñ Ğ² snake_case (Ğ´Ğ¾ 3 ÑĞ»Ğ¾Ğ²) Ğ´Ğ»Ñ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ "
                f"{method.upper()} {path}"
            )
            try:
                resp = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=6,
                    temperature=0,
                )
                name = resp.choices[0].message.content.strip().split()[0]
                names[op_id] = name
            except Exception as e:
                print("GPT name error:", e)
    return names


def filter_spec(spec: Dict, allowed: Set[Tuple[str, str]]) -> Dict:
    """Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒ ĞºĞ¾Ğ¿Ğ¸Ñ spec, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰ÑƒÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ allowed (path, method)."""
    s2 = copy.deepcopy(spec)
    for p in list(s2["paths"].keys()):
        for m in list(s2["paths"][p].keys()):
            if (p, m.lower()) not in allowed:
                s2["paths"][p].pop(m)
        if not s2["paths"][p]:
            s2["paths"].pop(p)
    return s2


def extract_ops(spec: Dict | None) -> Dict[str, Dict]:
    """Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ operation."""
    if not spec or not isinstance(spec, dict):
        return {}

    ops = {}
    for path, meths in spec.get("paths", {}).items():
        for method, op in meths.items():
            key = f"{method.lower()} {path}"
            op_id = op.get("operationId") or f"{method}_{path.strip('/').replace('/', '_')}"
            params = []
            for p in op.get("parameters", []):
                params.append(
                    {
                        "name": p.get("name", ""),
                        "in": p.get("in", ""),
                        "required": p.get("required", False),
                        "type": (
                            p.get("schema", {}).get("type")
                            if isinstance(p.get("schema"), dict)
                            else None
                        ),
                        "description": p.get("description", ""),
                    }
                )
            ops[key] = {
                "description": op.get("description", ""),
                "params": params,
                "operationId": op_id,
            }
    return ops


def ensure_spec(api: dict) -> bool:
    """Download and process spec if not already loaded."""
    if api.get("spec") or not api.get("url"):
        return False
    try:
        spec = load_openapi(api["url"])
    except Exception as e:
        api.setdefault("logs", []).append(f"Spec download error: {e}")
        return False

    gpt_describe(spec, OPENAI_ENV)
    api["mcp_names"] = gpt_mcp_names(spec, OPENAI_ENV)
    api["spec"] = spec
    api["operations"] = extract_ops(spec or {})
    eps = {(p, m.lower()) for p, v in spec.get("paths", {}).items() for m in v}
    if not api.get("enabled"):
        api["enabled"] = {f"{m} {p}": True for (p, m) in eps}
    save_state()
    return True


def make_http_client(base: str, headers: Dict, qparams: Dict, logger):
    """httpx.AsyncClient Ñ Ñ…ÑƒĞºĞ¾Ğ¼ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ."""

    def hook(resp: httpx.Response):
        logger(
            f"{resp.request.method} {resp.request.url} â†’ {resp.status_code}"
        )

    return httpx.AsyncClient(
        base_url=base,
        headers=headers,
        params=qparams,
        timeout=20,
        event_hooks={"response": [hook]},
    )


def log_line(api: dict, msg: str):
    api.setdefault("logs", []).append(f"{time.strftime('%H:%M:%S')}  {msg}")


def blank_api(name: str = "") -> Dict:
    """Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒ ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½ Ğ¿ÑƒÑÑ‚Ğ¾Ğ³Ğ¾ API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ ÑĞ¾ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸ĞµĞ¹ Ğ¸ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸."""
    return {
        "name": name,
        "url": "",
        "port": 8000,
        "header_name": "",
        "header_val": "",
        "query_name": "",
        "query_val": "",
        "spec": None,
        "operations": {},
        "enabled": {},
        "thread": None,
        "logs": [],
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Persist projects and API catalog to disk
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_FILE = "dashboard.json"
PROFILES_DIR = "profiles"  # Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ .json/.yaml Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸


def load_state():
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
        state["projects"] = data.get("projects", {})
        cats = data.get("api_catalog", {})
        state["api_catalog"] = {
            k: {
                **blank_api(k),
                **v,
                "thread": None,
                "logs": [],
                "operations": v.get(
                    "operations", extract_ops(v.get("spec") or {})
                ),
            }
            for k, v in cats.items()
        }
    else:
        state["projects"] = {}
        state["api_catalog"] = {}

    if os.path.isdir(PROFILES_DIR):
        for fn in os.listdir(PROFILES_DIR):
            if not fn.lower().endswith((".json", ".yaml", ".yml")):
                continue
            path = os.path.join(PROFILES_DIR, fn)
            with open(path, "r", encoding="utf-8") as f:
                txt = f.read()
            try:
                prof = json.loads(txt)
            except json.JSONDecodeError:
                prof = yaml.safe_load(txt)
            if isinstance(prof, dict) and prof.get("name"):
                state["api_catalog"][prof["name"]] = {
                    **blank_api(prof["name"]),
                    **prof,
                    "thread": None,
                    "logs": [],
                    "operations": prof.get(
                        "operations", extract_ops(prof.get("spec") or {})
                    ),
                }


def save_state():
    cats = {}
    for k, v in state.get("api_catalog", {}).items():
        v2 = {**v}
        v2.pop("thread", None)
        v2.pop("logs", None)
        if v2.get("spec") and not v2.get("operations"):
            v2["operations"] = extract_ops(v2.get("spec") or {})
        cats[k] = v2
        os.makedirs(PROFILES_DIR, exist_ok=True)
        with open(
            os.path.join(PROFILES_DIR, f"{k}.json"), "w", encoding="utf-8"
        ) as f:
            json.dump(v2, f, ensure_ascii=False, indent=2)
    data = {"projects": state.get("projects", {}), "api_catalog": cats}
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)



def start_mcp(api: dict):
    """Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ FastMCP Ğ´Ğ»Ñ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ."""
    ensure_spec(api)
    if not api.get("spec"):
        raise RuntimeError("Spec not loaded")
    if api.get("spec") and not api.get("operations"):
        api["operations"] = extract_ops(api.get("spec") or {})

    allowed = {
        (p, m.lower())
        for p, m in [
            k.split(" ", 1)[::-1] for k, v in api["enabled"].items() if v
        ]
    }
    spec_filtered = filter_spec(api["spec"], allowed)

    base = (api["spec"].get("servers", [{"url": ""}])[0]["url"]).rstrip("/")
    headers = (
        {api["header_name"]: api["header_val"]} if api["header_name"] else {}
    )
    qparams = (
        {api["query_name"]: api["query_val"]} if api["query_name"] else {}
    )

    client = make_http_client(
        base, headers, qparams, lambda m: log_line(api, m)
    )

    mcp = FastMCP.from_openapi(
        spec_filtered,
        client,
        name=api["name"],
        host="0.0.0.0",
        port=api["port"],
        mcp_names=api.get("mcp_names"),
    )

    def run_server():
        log_line(api, f"ğŸš€ MCP start :{api['port']}")
        mcp.run()

    t = threading.Thread(target=run_server, daemon=True)
    t.start()
    api["thread"] = t
    api["logs"] = []
    save_state()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ SESSION_STATE                                      #
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
load_dotenv()
OPENAI_ENV = os.getenv("OPENAI_API_KEY", "")

st.set_page_config(page_title="REST â†’ MCP", layout="wide")

state = st.session_state
load_state()
state.setdefault("projects", {})  # name â†’ project-dict
state.setdefault("api_catalog", {})  # Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸
state.setdefault("proj_sel", None)  # Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚
state.setdefault("api_sel", None)  # Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ
state.setdefault("chat", [])  # [(role, text)]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  SIDEBAR NAVIGATION                                               #
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PAGES = ["ğŸ’¬ Chat", "ğŸ”„ Convert", "ğŸ—‚ Projects", "âš™ï¸ API Setup"]
state.setdefault("page", PAGES[0])
with st.sidebar:
    for p in PAGES:
        if st.button(
            p,
            key=f"nav_{p}",
            type="primary" if state["page"] == p else "secondary",
            use_container_width=True,
        ):
            state["page"] = p
            rerun()
    st.divider()
    if state.get("proj_sel"):
        st.success(f"ĞŸÑ€Ğ¾ĞµĞºÑ‚: {state['proj_sel']}")
    else:
        st.info("ĞŸÑ€Ğ¾ĞµĞºÑ‚ Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½")
page = state["page"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Projects â”€â”€â”€
if page == "ğŸ—‚ Projects":
    st.header("ğŸ—‚ Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ğ¼Ğ¸")

    proj_names = list(state["projects"])
    chosen = st.selectbox(
        "ĞŸÑ€Ğ¾ĞµĞºÑ‚",
        ["< ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ >"] + proj_names,
        index=(
            proj_names.index(state["proj_sel"]) + 1
            if state["proj_sel"] in proj_names
            else 0
        ),
    )
    creating_new = chosen == "< ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ >"

    project = (
        {"name": "", "openai": OPENAI_ENV, "apis": []}
        if creating_new
        else state["projects"][chosen]
    )
    with st.form("proj_form"):
        project["name"] = st.text_input("ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°", project["name"])
        project["openai"] = st.text_input(
            "OpenAI API-ĞºĞ»ÑÑ‡",
            project["openai"],
            type="password",
            help="ĞŸÑƒÑÑ‚Ğ¾ â†’ Ğ±ĞµÑ€Ñ‘Ñ‚ÑÑ Ğ¸Ğ· .env",
        )
        if st.form_submit_button(
            "ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚", type="primary", use_container_width=True
        ):
            if not project["name"]:
                st.warning("Ğ˜Ğ¼Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾.")
            else:
                state["projects"][project["name"]] = project
                state["proj_sel"] = project["name"]
                save_state()
                rerun()

    if not creating_new:
        st.divider()
        st.subheader("ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸")
        sel = st.multiselect(
            "Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸",
            list(state["api_catalog"]),
            default=project.get("apis", []),
            key="proj_api_ms",
        )
        if st.button(
            "ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº",
            key="proj_api_save",
            use_container_width=True,
        ):
            project["apis"] = sel
            state["projects"][project["name"]] = project
            save_state()
            rerun()

        st.subheader("Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸")
        for api_name in project.get("apis", []):
            cfg = state["api_catalog"].get(api_name)
            if not cfg:
                continue
            running = cfg.get("thread") and cfg["thread"].is_alive()
            badge = "âœ…" if running else "â¹"
            st.write(
                f"{badge} **{api_name}**  â€”  {cfg['url']}  (:{cfg['port']})"
            )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ API Setup â”€â”€
elif page == "âš™ï¸ API Setup":
    st.header("âš™ï¸ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ")

    api_names = list(state["api_catalog"])
    choice = st.selectbox(
        "ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ",
        ["< ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ >"] + api_names,
        index=(
            api_names.index(state["api_sel"]) + 1
            if state["api_sel"] in api_names
            else 0
        ),
        key="api_choice",
    )

    creating = choice == "< ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ >"

    if creating:
        api = state.get("new_api", blank_api())
        uploaded = st.file_uploader(
            "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°", type=["json", "yaml", "yml"], key="prof_up"
        )
        if uploaded:
            try:
                txt = uploaded.read().decode()
                try:
                    prof = json.loads(txt)
                except json.JSONDecodeError:
                    prof = yaml.safe_load(txt)
                if isinstance(prof, dict):
                    api = blank_api()
                    api.update(prof)
                    if api.get("spec") and not api.get("operations"):
                        api["operations"] = extract_ops(api.get("spec") or {})
                    st.success("Ğ¤Ğ°Ğ¹Ğ» Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½")
            except Exception as e:
                st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°: {e}")
    else:
        state["api_sel"] = choice
        api = state["api_catalog"][choice]
        res = ensure_spec(api)
        if res:
            rerun()
        elif not api.get("spec"):
            st.error("ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ°")

    with st.form("api_form"):
        col1, col2 = st.columns(2)
        with col1:
            api["name"] = st.text_input("API-Ğ¸Ğ¼Ñ", api["name"], key="f_name")
            api["url"] = st.text_input("URL", api["url"], key="f_url")
            api["port"] = st.number_input(
                "ĞŸĞ¾Ñ€Ñ‚ MCP", 1024, 65535, api["port"], key="f_port"
            )
        with col2:
            api["header_name"] = st.text_input(
                "Auth header", api["header_name"], key="f_hn"
            )
            api["header_val"] = st.text_input(
                "Header value", api["header_val"], key="f_hv"
            )
            api["query_name"] = st.text_input(
                "Auth query", api["query_name"], key="f_qn"
            )
            api["query_val"] = st.text_input(
                "Query value", api["query_val"], key="f_qv"
            )
        btn_label = "â• Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ" if creating else "ğŸ’¾ ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ"
        if st.form_submit_button(
            btn_label, type="primary", use_container_width=True
        ):
            if not api["name"] or not api["url"]:
                st.warning("Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Ğ¸Ğ¼Ñ Ğ¸ URL ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸.")
            elif creating and api["name"] in state["api_catalog"]:
                st.warning("Ğ¢Ğ°ĞºĞ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚.")
            else:
                state["api_catalog"][api["name"]] = api
                state["api_sel"] = api["name"]
                state["new_api"] = blank_api()
                save_state()
                rerun()

    if creating:
        state["new_api"] = api
    else:
        api = state["api_catalog"][state["api_sel"]]
        st.divider()
        if st.button(
            "ğŸ”„ ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ",
            type="primary",
            use_container_width=True,
            key="dl_spec",
        ):
            result = ensure_spec(api)
            if result:
                rerun()
            elif not api.get("spec"):
                st.error("ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ°")

        if api.get("spec"):
            st.subheader("Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ/Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹")
            if st.button("ğŸ§  Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ¼ĞµĞ½Ğ°", key="gen_names"):
                api["mcp_names"] = gpt_mcp_names(api["spec"], OPENAI_ENV)
                save_state()
                rerun()
            ops = api.get("operations", {})
            with st.form("ep_form"):
                for path, meths in api["spec"]["paths"].items():
                    for method, op in meths.items():
                        if method.lower() not in ("get", "post"):
                            continue
                        key = f"{method} {path}"
                        info = ops.get(key, {})
                        label = f"{method.upper()} {path}"
                        op_id = info.get("operationId") or op.get("operationId")
                        tool_name = api.get("mcp_names", {}).get(op_id, "") if op_id else ""
                        if tool_name:
                            label += f" â†’ {tool_name}"
                        if info.get("description"):
                            label += f" â€” {info['description']}"
                        with st.expander(label, expanded=True):
                            api["enabled"][key] = st.checkbox(
                                "Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ",
                                value=api["enabled"].get(key, False),
                                key=f"en_{key}",
                            )
                            if info.get("params"):
                                for prm in info["params"]:
                                    if not prm.get("name"):
                                        continue
                                    desc = f"**{prm['name']}**"
                                    if prm.get("type"):
                                        desc += f" `{prm['type']}`"
                                    if prm.get("required"):
                                        desc += " (required)"
                                    if prm.get("description"):
                                        desc += f": {prm['description']}"
                                    st.markdown(f"- {desc}")
                if st.form_submit_button(
                    "ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ", use_container_width=True
                ):
                    save_state()
                    rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONVERT â”€â”€â”€
elif page == "ğŸ”„ Convert":
    st.header("ğŸ”„ Convert")
    st.info(
        "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ²Ğ¾ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞµ Â«API SetupÂ», Ğ·Ğ°Ğ¿ÑƒÑĞº MCP â€” Ğ²Ğ¾ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞµ Â«ChatÂ»."
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CHAT â”€â”€â”€â”€â”€â”€
elif page == "ğŸ’¬ Chat":
    st.header("ğŸ’¬ Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ñ‡Ğ°Ñ‚ Ñ MCP")

    all_servers = [
        (pj_name, api_name, state["api_catalog"][api_name])
        for pj_name, pj in state["projects"].items()
        for api_name in pj.get("apis", [])
        if api_name in state["api_catalog"]
    ]
    if not all_servers:
        st.info("ĞĞµÑ‚ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ñ… API-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹.")
        st.stop()

    options = [
        f"{pj}/{api}  (:{cfg['port']})"
        + (" âœ…" if cfg.get("thread") and cfg["thread"].is_alive() else " â¹")
        for pj, api, cfg in all_servers
    ]
    sel_label = st.selectbox("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ MCP-Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ", options)
    pj_name, api_name = sel_label.split("  ")[0].split("/")
    chat_cfg = state["api_catalog"][api_name]
    running = chat_cfg.get("thread") and chat_cfg["thread"].is_alive()

    if st.button("ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ / ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ MCP", use_container_width=True):
        try:
            start_mcp(chat_cfg)
        except Exception as e:
            st.error(f"FastMCP error: {e}")
        rerun()

    if not running:
        st.info("Ğ¡ĞµÑ€Ğ²ĞµÑ€ Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½.")
        st.stop()

    port = chat_cfg["port"]

    # Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸
    for role, msg in state["chat"]:
        st.chat_message(role).markdown(msg)

    user_msg = st.chat_input("Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµâ€¦")
    if user_msg:
        state["chat"].append(("user", user_msg))
        st.chat_message("user").markdown(user_msg)

        # Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ tools /tools/list
        try:
            tools_json = requests.post(
                f"http://localhost:{port}/tools/list", timeout=10
            ).json()
            tools = tools_json["tools"]
        except Exception as e:
            st.error(f"/tools/list error: {e}")
            st.stop()

        functions = [
            {
                "name": t["name"],
                "description": t["description"],
                "parameters": t["input_schema"],
            }
            for t in tools
        ]

        openai.api_key = state["projects"][pj_name]["openai"] or OPENAI_ENV
        conv = [
            {
                "role": "system",
                "content": "ĞŸÑ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ MCP-tools.",
            }
        ] + [{"role": r, "content": m} for r, m in state["chat"]]

        while True:
            resp = openai.ChatCompletion.create(
                model="gpt-3.5-turbo-1106", messages=conv, functions=functions
            )
            msg = resp.choices[0].message

            # ĞµÑĞ»Ğ¸ GPT Ñ…Ğ¾Ñ‡ĞµÑ‚ Ğ²Ñ‹Ğ·Ğ²Ğ°Ñ‚ÑŒ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ
            if "function_call" in msg:
                fc = msg.function_call
                args = json.loads(fc.arguments or "{}")
                try:
                    result = requests.post(
                        f"http://localhost:{port}/tools/call",
                        json={"name": fc.name, "arguments": args},
                        timeout=30,
                    ).json()
                    tool_answer = result["content"][0]["text"]
                except Exception as e:
                    tool_answer = f"âš ï¸ MCP error: {e}"

                conv.append(
                    {
                        "role": "assistant",
                        "name": fc.name,
                        "content": None,
                        "function_call": fc,
                    }
                )
                conv.append(
                    {
                        "role": "function",
                        "name": fc.name,
                        "content": tool_answer,
                    }
                )
            else:
                answer = msg.content
                state["chat"].append(("assistant", answer))
                st.chat_message("assistant").markdown(answer)
                break
